{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Compact SchNet-style PyTorch script for predicting scene density (per-scene N/volume)\n",
    "# - Pure PyTorch, no external GNN libraries\n",
    "# - Generates random scenes, trains small SchNet-like model, plots training/validation loss\n",
    "# - Saves model to /mnt/data/schnet_density.pth\n",
    "# Run where PyTorch and matplotlib are available.\n",
    "\n",
    "import math, random, time, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# ---------------- Data: random scenes ----------------\n",
    "class RandomSceneDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, n_scenes, min_atoms=5, max_atoms=60, min_box=3.0, max_box=8.0, seed=None\n",
    "    ):\n",
    "        self.scenes = []\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "        for _ in range(n_scenes):\n",
    "            N = random.randint(min_atoms, max_atoms)\n",
    "            side = random.uniform(min_box, max_box)\n",
    "            pos = torch.rand(N, 3) * side  # uniform inside cube\n",
    "            volume = side**3\n",
    "            density = N / volume\n",
    "            # use a single dummy atom type (all zeros) â€” easy to extend to multiple types\n",
    "            Z = torch.zeros(N, dtype=torch.long)\n",
    "            self.scenes.append(\n",
    "                {\"pos\": pos, \"Z\": Z, \"side\": side, \"volume\": volume, \"density\": density}\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scenes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.scenes[idx]\n",
    "        return (\n",
    "            s[\"pos\"],\n",
    "            s[\"Z\"],\n",
    "            s[\"volume\"],\n",
    "            torch.tensor([s[\"density\"]], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch: list of (pos, Z, volume, density)\n",
    "    positions = []\n",
    "    Zs = []\n",
    "    volumes = []\n",
    "    densities = []\n",
    "    batch_idx = []\n",
    "    for i, (pos, Z, vol, dens) in enumerate(batch):\n",
    "        positions.append(pos)\n",
    "        Zs.append(Z)\n",
    "        volumes.append(vol)\n",
    "        densities.append(dens)\n",
    "        batch_idx.append(torch.full((pos.shape[0],), i, dtype=torch.long))\n",
    "    positions = torch.cat(positions, dim=0)\n",
    "    Zs = torch.cat(Zs, dim=0)\n",
    "    batch_idx = torch.cat(batch_idx, dim=0)\n",
    "    volumes = torch.tensor(volumes, dtype=torch.float32)\n",
    "    densities = torch.cat(densities, dim=0)\n",
    "    return positions, Zs, batch_idx, volumes, densities\n",
    "\n",
    "\n",
    "# ---------------- radial basis (Gaussian RBF) ----------------\n",
    "class GaussianRBF(nn.Module):\n",
    "    def __init__(self, centers, gamma):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"centers\", torch.tensor(centers).float())\n",
    "        self.gamma = float(gamma)\n",
    "\n",
    "    def forward(self, d):\n",
    "        # d: (E,) or (...,)\n",
    "        c = self.centers.to(d.device)\n",
    "        return torch.exp(-self.gamma * (d.unsqueeze(-1) - c) ** 2)  # (..., K)\n",
    "\n",
    "\n",
    "# ---------------- radius graph (batched) ----------------\n",
    "# --- Fixed radius_graph (keeps everything on the same device) ---\n",
    "def radius_graph(positions, batch, cutoff):\n",
    "    # positions: (TotalNodes,3) tensor on some device\n",
    "    device = positions.device\n",
    "    edge_src = []\n",
    "    edge_dst = []\n",
    "    edge_vec = []\n",
    "    edge_dist = []\n",
    "    unique = batch.unique(sorted=True)\n",
    "    for b in unique:\n",
    "        # b is a scalar tensor on 'device'\n",
    "        idx = (batch == b).nonzero(as_tuple=True)[0]  # indices on same device\n",
    "        if idx.numel() <= 1:\n",
    "            continue\n",
    "        pos_b = positions[idx]  # (n_b,3) on device\n",
    "        diff = pos_b.unsqueeze(1) - pos_b.unsqueeze(0)  # (n_b,n_b,3)\n",
    "        dist2 = (diff**2).sum(dim=-1)  # (n_b,n_b)\n",
    "        n_b = pos_b.shape[0]\n",
    "        # create eye on same device\n",
    "        mask = (~torch.eye(n_b, dtype=torch.bool, device=device)) & (\n",
    "            dist2 <= cutoff * cutoff\n",
    "        )\n",
    "        src_local, dst_local = mask.nonzero(as_tuple=True)\n",
    "        if src_local.numel() == 0:\n",
    "            continue\n",
    "        src_global = idx[src_local]\n",
    "        dst_global = idx[dst_local]\n",
    "        rel = positions[dst_global] - positions[src_global]\n",
    "        dist = torch.sqrt((rel**2).sum(dim=-1) + 1e-8)\n",
    "        edge_src.append(src_global)\n",
    "        edge_dst.append(dst_global)\n",
    "        edge_vec.append(rel)\n",
    "        edge_dist.append(dist)\n",
    "    if len(edge_src) == 0:\n",
    "        # ensure returned tensors are on the same device\n",
    "        return (\n",
    "            torch.zeros((2, 0), dtype=torch.long, device=device),\n",
    "            torch.zeros((0, 3), device=device),\n",
    "            torch.zeros((0,), device=device),\n",
    "        )\n",
    "    edge_src = torch.cat(edge_src)\n",
    "    edge_dst = torch.cat(edge_dst)\n",
    "    edge_vec = torch.cat(edge_vec)\n",
    "    edge_dist = torch.cat(edge_dist)\n",
    "    edge_index = torch.stack([edge_src, edge_dst], dim=0)\n",
    "    return edge_index, edge_vec, edge_dist\n",
    "\n",
    "\n",
    "# ---------------- SchNet-like blocks ----------------\n",
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, rbf_dim):\n",
    "        super().__init__()\n",
    "        self.filter_net = nn.Sequential(\n",
    "            nn.Linear(rbf_dim, hidden_dim), nn.SiLU(), nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.dense = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.update = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, rbf):\n",
    "        # x: (N,H), edge_index: (2,E), rbf: (E,K)\n",
    "        src, dst = edge_index\n",
    "        filters = self.filter_net(rbf)  # (E,H)\n",
    "        x_src = x[src]  # (E,H)\n",
    "        msg = self.dense(x_src) * filters  # (E,H) elementwise\n",
    "        agg = torch.zeros_like(x)\n",
    "        agg = agg.index_add(0, dst, msg)  # sum aggregate to dst nodes\n",
    "        out = self.update(torch.cat([x, agg], dim=-1)) + x\n",
    "        return out\n",
    "\n",
    "\n",
    "class SchNetDensity(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_atom_types=1,\n",
    "        hidden_dim=64,\n",
    "        rbf_centers=None,\n",
    "        gamma=10.0,\n",
    "        n_interactions=3,\n",
    "        cutoff=2.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if rbf_centers is None:\n",
    "            rbf_centers = torch.linspace(0.0, 6.0, 24)\n",
    "        self.embed = nn.Embedding(n_atom_types, hidden_dim)\n",
    "        self.rbf = GaussianRBF(rbf_centers, gamma)\n",
    "        self.interactions = nn.ModuleList(\n",
    "            [\n",
    "                InteractionBlock(hidden_dim, len(rbf_centers))\n",
    "                for _ in range(n_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.atom_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def forward(self, positions, Z, batch, volumes):\n",
    "        # positions: (TotalNodes,3) on some device; Z and batch should be same device\n",
    "        device = positions.device\n",
    "        x = self.embed(Z)  # (N,H) on device\n",
    "        edge_index, edge_vec, edge_dist = radius_graph(positions, batch, self.cutoff)\n",
    "        if edge_index.numel() > 0:\n",
    "            rbf = self.rbf(edge_dist)  # (E, K) on same device\n",
    "            for block in self.interactions:\n",
    "                x = block(x, edge_index, rbf)\n",
    "        per_atom = self.atom_out(x).squeeze(-1)  # (N,) on device\n",
    "\n",
    "        # Sum per-atom contributions per graph (device-safe)\n",
    "        if batch.numel() == 0:\n",
    "            return torch.zeros((0,), device=device), per_atom\n",
    "\n",
    "        batch_size = int(batch.max().item()) + 1\n",
    "        graph_sum = torch.zeros(batch_size, device=device)  # (B,)\n",
    "        graph_sum = graph_sum.index_add(0, batch.to(device), per_atom)  # sum per graph\n",
    "        pred_density = graph_sum / volumes.to(device)  # volumes -> device\n",
    "        return pred_density, per_atom\n",
    "\n",
    "\n",
    "# ---------------- training utilities ----------------\n",
    "def train_epoch(model, loader, opt, criterion):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    n = 0\n",
    "    for positions, Z, batch_idx, volumes, dens in loader:\n",
    "        positions = positions.to(device)\n",
    "        Z = Z.to(device)\n",
    "        batch_idx = batch_idx.to(device)\n",
    "        volumes = volumes.to(device)\n",
    "        dens = dens.to(device).squeeze(-1)\n",
    "        opt.zero_grad()\n",
    "        pred, _ = model(positions, Z, batch_idx, volumes)\n",
    "        loss = criterion(pred, dens)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running += loss.item() * dens.shape[0]\n",
    "        n += dens.shape[0]\n",
    "    return running / n\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for positions, Z, batch_idx, volumes, dens in loader:\n",
    "            positions = positions.to(device)\n",
    "            Z = Z.to(device)\n",
    "            batch_idx = batch_idx.to(device)\n",
    "            volumes = volumes.to(device)\n",
    "            dens = dens.to(device).squeeze(-1)\n",
    "            pred, _ = model(positions, Z, batch_idx, volumes)\n",
    "            loss = criterion(pred, dens)\n",
    "            running += loss.item() * dens.shape[0]\n",
    "            n += dens.shape[0]\n",
    "    return running / n\n",
    "\n",
    "\n",
    "# ---------------- create datasets & loaders ----------------\n",
    "train_ds = RandomSceneDataset(\n",
    "    1000, min_atoms=5, max_atoms=60, min_box=3.0, max_box=12.0, seed=0\n",
    ")\n",
    "val_ds = RandomSceneDataset(\n",
    "    1000, min_atoms=5, max_atoms=60, min_box=3.0, max_box=12.0, seed=1\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ---------------- instantiate and train model ----------------\n",
    "model = SchNetDensity(\n",
    "    n_atom_types=1,\n",
    "    hidden_dim=48,\n",
    "    rbf_centers=torch.linspace(0.0, 6.0, 20),\n",
    "    gamma=8.0,\n",
    "    n_interactions=2,\n",
    "    cutoff=2.5,\n",
    ")\n",
    "model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "epochs = 30\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "t0 = time.time()\n",
    "for ep in range(1, epochs + 1):\n",
    "    tr = train_epoch(model, train_loader, opt, criterion)\n",
    "    va = eval_epoch(model, val_loader, criterion)\n",
    "    train_losses.append(tr)\n",
    "    val_losses.append(va)\n",
    "    print(f\"Epoch {ep}/{epochs}  train={tr:.6e}  val={va:.6e}\")\n",
    "print(\"Total training time: {:.1f}s\".format(time.time() - t0))\n",
    "\n",
    "# ---------------- plot losses ----------------\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relative RMSE\")\n",
    "plt.title(\"Density training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ---------------- example predictions ----------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    positions, Z, batch_idx, volumes, dens = next(iter(val_loader))\n",
    "    pred, per_atom = model(\n",
    "        positions.to(device), Z.to(device), batch_idx.to(device), volumes.to(device)\n",
    "    )\n",
    "    print(\"\\nExample predictions (first batch):\")\n",
    "    for i in range(min(8, pred.shape[0])):\n",
    "        print(\n",
    "            f\"pred={pred[i].item():.6f}  true={dens[i].item():.6f}  side={(volumes[i]**(1/3)):.3f}  N_est={ (pred[i].item()*volumes[i]).round() }\"\n",
    "        )\n",
    "\n",
    "# ---------------- save model ----------------\n",
    "path = \"./schnet_density.pth\"\n",
    "torch.save({\"model_state\": model.state_dict(), \"args\": {\"hidden_dim\": 48}}, path)\n",
    "print(\"Saved model to\", path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
